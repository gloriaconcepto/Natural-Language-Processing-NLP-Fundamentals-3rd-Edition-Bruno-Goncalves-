{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gloriaconcepto/Natural-Language-Processing-NLP-Fundamentals-3rd-Edition-Bruno-Goncalves-/blob/main/nlp_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUOgXn8leg-R",
        "outputId": "29fbde29-cc51-4a5e-babd-8c675f1e1ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0P-Nn2g6cX",
        "outputId": "ec90e1d4-b882-46d5-9a8c-9a1097773576"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e278ec93"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Mary had a little lamb,\n",
        "Little lamb, little lamb,\n",
        "Mary had a little lamb,\n",
        "Its fleece was white as snow.\n",
        "\n",
        "And everywhere that Mary went,\n",
        "Mary went, Mary went,\n",
        "Everywhere that Mary went,\n",
        "The lamb was sure to go.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zU6KGmwgASZ",
        "outputId": "6006a724-1ed1-4838-f111-643b282a5be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mary', 'had', 'a', 'little', 'lamb', ',', 'Little', 'lamb', ',', 'little', 'lamb', ',', 'Mary', 'had', 'a', 'little', 'lamb', ',', 'Its', 'fleece', 'was', 'white', 'as', 'snow', '.', 'And', 'everywhere', 'that', 'Mary', 'went', ',', 'Mary', 'went', ',', 'Mary', 'went', ',', 'Everywhere', 'that', 'Mary', 'went', ',', 'The', 'lamb', 'was', 'sure', 'to', 'go', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize,WordPunctTokenizer\n",
        "tokens =word_tokenize(text, 'english')\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI_utRSshc8t",
        "outputId": "b1b4f1d2-1e63-4d2e-cd43-bf438ce39acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mary had a little lamb,\\nLittle lamb, little lamb,\\nMary had a little lamb,\\nIts fleece was white as snow.', 'And everywhere that Mary went,\\nMary went, Mary went,\\nEverywhere that Mary went,\\nThe lamb was sure to go.']\n"
          ]
        }
      ],
      "source": [
        "#  i can use a sentence tokenize to group it into sentences or words....\n",
        "sentences = sent_tokenize(text, 'english')\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_tQ5NbThyS3",
        "outputId": "5859c445-f98b-43c3-a95a-be321d3dc294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary\n"
          ]
        }
      ],
      "source": [
        "print(tokens[12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8yfL1JFjiip",
        "outputId": "d5799f7a-7630-4477-dce7-35f863cc7e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mary', 'had', 'a', 'little', 'lamb', ',', 'Little', 'lamb', ',', 'little', 'lamb', ',', 'Mary', 'had', 'a', 'little', 'lamb', ',', 'Its', 'fleece', 'was', 'white', 'as', 'snow', '.', 'And', 'everywhere', 'that', 'Mary', 'went', ',', 'Mary', 'went', ',', 'Mary', 'went', ',', 'Everywhere', 'that', 'Mary', 'went', ',', 'The', 'lamb', 'was', 'sure', 'to', 'go', '.']\n"
          ]
        }
      ],
      "source": [
        "tokens = WordPunctTokenizer().tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-rXtCltluki"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def tokenize(text,preserve_case=True):\n",
        "    punctuation=set(string.punctuation)\n",
        "    text_words=[]\n",
        "\n",
        "    for word in nltk.tokenize.WordPunctTokenizer().tokenize(text):\n",
        "      if word in punctuation:\n",
        "        continue\n",
        "\n",
        "      if preserve_case:\n",
        "         text_words.append(word)\n",
        "      else:\n",
        "          text_words.append(word.lower())\n",
        "\n",
        "    return text_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRxjKbORm4OX",
        "outputId": "e4e22b7b-0940-43e8-ece8-c756a51ae97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['mary', 'had', 'a', 'little', 'lamb', 'little', 'lamb', 'little', 'lamb', 'mary', 'had', 'a', 'little', 'lamb', 'its', 'fleece', 'was', 'white', 'as', 'snow', 'and', 'everywhere', 'that', 'mary', 'went', 'mary', 'went', 'mary', 'went', 'everywhere', 'that', 'mary', 'went', 'the', 'lamb', 'was', 'sure', 'to', 'go']\n"
          ]
        }
      ],
      "source": [
        "text_words=tokenize(text,False)\n",
        "print(text_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "qwLLgAjOnhiK",
        "outputId": "4113f081-3955-4db7-f2c8-342ade7ff0b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"one_hot\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"and\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"as\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"everywhere\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fleece\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"go\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"had\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"its\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lamb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"little\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"that\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"to\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"was\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"went\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"white\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "one_hot"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-066da914-d9dd-4969-b053-0096a7ccda0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>and</th>\n",
              "      <th>as</th>\n",
              "      <th>everywhere</th>\n",
              "      <th>fleece</th>\n",
              "      <th>go</th>\n",
              "      <th>had</th>\n",
              "      <th>its</th>\n",
              "      <th>lamb</th>\n",
              "      <th>little</th>\n",
              "      <th>mary</th>\n",
              "      <th>snow</th>\n",
              "      <th>sure</th>\n",
              "      <th>that</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>was</th>\n",
              "      <th>went</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-066da914-d9dd-4969-b053-0096a7ccda0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-066da914-d9dd-4969-b053-0096a7ccda0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-066da914-d9dd-4969-b053-0096a7ccda0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-951f2437-5087-4071-b037-064d2e8d5bca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-951f2437-5087-4071-b037-064d2e8d5bca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-951f2437-5087-4071-b037-064d2e8d5bca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d8d9c814-f721-4609-85a8-7e3688304939\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('one_hot')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d8d9c814-f721-4609-85a8-7e3688304939 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('one_hot');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    a  and  as  everywhere  fleece  go  had  its  lamb  little  mary  snow  \\\n",
              "0   0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "1   0    0   0           0       0   0    1    0     0       0     0     0   \n",
              "2   1    0   0           0       0   0    0    0     0       0     0     0   \n",
              "3   0    0   0           0       0   0    0    0     0       1     0     0   \n",
              "4   0    0   0           0       0   0    0    0     1       0     0     0   \n",
              "5   0    0   0           0       0   0    0    0     0       1     0     0   \n",
              "6   0    0   0           0       0   0    0    0     1       0     0     0   \n",
              "7   0    0   0           0       0   0    0    0     0       1     0     0   \n",
              "8   0    0   0           0       0   0    0    0     1       0     0     0   \n",
              "9   0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "10  0    0   0           0       0   0    1    0     0       0     0     0   \n",
              "11  1    0   0           0       0   0    0    0     0       0     0     0   \n",
              "12  0    0   0           0       0   0    0    0     0       1     0     0   \n",
              "13  0    0   0           0       0   0    0    0     1       0     0     0   \n",
              "14  0    0   0           0       0   0    0    1     0       0     0     0   \n",
              "15  0    0   0           0       1   0    0    0     0       0     0     0   \n",
              "16  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "17  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "18  0    0   1           0       0   0    0    0     0       0     0     0   \n",
              "19  0    0   0           0       0   0    0    0     0       0     0     1   \n",
              "20  0    1   0           0       0   0    0    0     0       0     0     0   \n",
              "21  0    0   0           1       0   0    0    0     0       0     0     0   \n",
              "22  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "23  0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "24  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "25  0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "26  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "27  0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "28  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "29  0    0   0           1       0   0    0    0     0       0     0     0   \n",
              "30  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "31  0    0   0           0       0   0    0    0     0       0     1     0   \n",
              "32  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "33  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "34  0    0   0           0       0   0    0    0     1       0     0     0   \n",
              "35  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "36  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "37  0    0   0           0       0   0    0    0     0       0     0     0   \n",
              "38  0    0   0           0       0   1    0    0     0       0     0     0   \n",
              "\n",
              "    sure  that  the  to  was  went  white  \n",
              "0      0     0    0   0    0     0      0  \n",
              "1      0     0    0   0    0     0      0  \n",
              "2      0     0    0   0    0     0      0  \n",
              "3      0     0    0   0    0     0      0  \n",
              "4      0     0    0   0    0     0      0  \n",
              "5      0     0    0   0    0     0      0  \n",
              "6      0     0    0   0    0     0      0  \n",
              "7      0     0    0   0    0     0      0  \n",
              "8      0     0    0   0    0     0      0  \n",
              "9      0     0    0   0    0     0      0  \n",
              "10     0     0    0   0    0     0      0  \n",
              "11     0     0    0   0    0     0      0  \n",
              "12     0     0    0   0    0     0      0  \n",
              "13     0     0    0   0    0     0      0  \n",
              "14     0     0    0   0    0     0      0  \n",
              "15     0     0    0   0    0     0      0  \n",
              "16     0     0    0   0    1     0      0  \n",
              "17     0     0    0   0    0     0      1  \n",
              "18     0     0    0   0    0     0      0  \n",
              "19     0     0    0   0    0     0      0  \n",
              "20     0     0    0   0    0     0      0  \n",
              "21     0     0    0   0    0     0      0  \n",
              "22     0     1    0   0    0     0      0  \n",
              "23     0     0    0   0    0     0      0  \n",
              "24     0     0    0   0    0     1      0  \n",
              "25     0     0    0   0    0     0      0  \n",
              "26     0     0    0   0    0     1      0  \n",
              "27     0     0    0   0    0     0      0  \n",
              "28     0     0    0   0    0     1      0  \n",
              "29     0     0    0   0    0     0      0  \n",
              "30     0     1    0   0    0     0      0  \n",
              "31     0     0    0   0    0     0      0  \n",
              "32     0     0    0   0    0     1      0  \n",
              "33     0     0    1   0    0     0      0  \n",
              "34     0     0    0   0    0     0      0  \n",
              "35     0     0    0   0    1     0      0  \n",
              "36     1     0    0   0    0     0      0  \n",
              "37     0     0    0   1    0     0      0  \n",
              "38     0     0    0   0    0     0      0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "one_hot = pd.get_dummies(text_words,dtype=int)\n",
        "one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SdlgEU-cpWfJ",
        "outputId": "433d31c6-9264-42a8-b472-1090e7457009"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"temp\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"and\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"as\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"everywhere\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fleece\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"go\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"had\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"its\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lamb\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"little\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snow\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sure\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"that\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"to\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"was\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"went\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"white\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "temp"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2e7d59df-cfb3-4f6b-a38e-ec0c0e29fe4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>and</th>\n",
              "      <th>as</th>\n",
              "      <th>everywhere</th>\n",
              "      <th>fleece</th>\n",
              "      <th>go</th>\n",
              "      <th>had</th>\n",
              "      <th>its</th>\n",
              "      <th>lamb</th>\n",
              "      <th>little</th>\n",
              "      <th>mary</th>\n",
              "      <th>snow</th>\n",
              "      <th>sure</th>\n",
              "      <th>that</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "      <th>was</th>\n",
              "      <th>went</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e7d59df-cfb3-4f6b-a38e-ec0c0e29fe4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e7d59df-cfb3-4f6b-a38e-ec0c0e29fe4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e7d59df-cfb3-4f6b-a38e-ec0c0e29fe4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f11d3c2-3c91-4199-8c2d-7fc827be48e7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f11d3c2-3c91-4199-8c2d-7fc827be48e7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f11d3c2-3c91-4199-8c2d-7fc827be48e7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cce8d5ed-89a5-4d0a-b71b-4065441e6e5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('temp')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cce8d5ed-89a5-4d0a-b71b-4065441e6e5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('temp');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    a and as everywhere fleece go had its lamb little mary snow sure that the  \\\n",
              "0                                                        1                      \n",
              "1                                   1                                           \n",
              "2   1                                                                           \n",
              "3                                                   1                           \n",
              "4                                            1                                  \n",
              "5                                                   1                           \n",
              "6                                            1                                  \n",
              "7                                                   1                           \n",
              "8                                            1                                  \n",
              "9                                                        1                      \n",
              "10                                  1                                           \n",
              "11  1                                                                           \n",
              "12                                                  1                           \n",
              "13                                           1                                  \n",
              "14                                      1                                       \n",
              "15                           1                                                  \n",
              "16                                                                              \n",
              "17                                                                              \n",
              "18         1                                                                    \n",
              "19                                                            1                 \n",
              "20      1                                                                       \n",
              "21                    1                                                         \n",
              "22                                                                      1       \n",
              "23                                                       1                      \n",
              "24                                                                              \n",
              "25                                                       1                      \n",
              "26                                                                              \n",
              "27                                                       1                      \n",
              "28                                                                              \n",
              "29                    1                                                         \n",
              "30                                                                      1       \n",
              "31                                                       1                      \n",
              "32                                                                              \n",
              "33                                                                          1   \n",
              "34                                           1                                  \n",
              "35                                                                              \n",
              "36                                                                 1            \n",
              "37                                                                              \n",
              "38                              1                                               \n",
              "\n",
              "   to was went white  \n",
              "0                     \n",
              "1                     \n",
              "2                     \n",
              "3                     \n",
              "4                     \n",
              "5                     \n",
              "6                     \n",
              "7                     \n",
              "8                     \n",
              "9                     \n",
              "10                    \n",
              "11                    \n",
              "12                    \n",
              "13                    \n",
              "14                    \n",
              "15                    \n",
              "16      1             \n",
              "17                 1  \n",
              "18                    \n",
              "19                    \n",
              "20                    \n",
              "21                    \n",
              "22                    \n",
              "23                    \n",
              "24           1        \n",
              "25                    \n",
              "26           1        \n",
              "27                    \n",
              "28           1        \n",
              "29                    \n",
              "30                    \n",
              "31                    \n",
              "32           1        \n",
              "33                    \n",
              "34                    \n",
              "35      1             \n",
              "36                    \n",
              "37  1                 \n",
              "38                    "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp=one_hot.astype('str');\n",
        "temp[temp=='0']=\"\"\n",
        "temp=pd.DataFrame(temp)\n",
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b714afe5",
        "outputId": "92d2a3d6-0d60-4de3-cbc5-7a034a3e8bea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': 0,\n",
              " 'and': 1,\n",
              " 'as': 2,\n",
              " 'everywhere': 3,\n",
              " 'fleece': 4,\n",
              " 'go': 5,\n",
              " 'had': 6,\n",
              " 'its': 7,\n",
              " 'lamb': 8,\n",
              " 'little': 9,\n",
              " 'mary': 10,\n",
              " 'snow': 11,\n",
              " 'sure': 12,\n",
              " 'that': 13,\n",
              " 'the': 14,\n",
              " 'to': 15,\n",
              " 'was': 16,\n",
              " 'went': 17,\n",
              " 'white': 18}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_id_from_one_hot = {\n",
        "    word: int(idx) for word, idx in zip(one_hot.columns, np.arange(one_hot.shape[1]))\n",
        "}\n",
        "word_to_id_from_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1100da5",
        "outputId": "2aa5ff2f-4546-4ecf-f671-7c06f44d6fc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(tokens, language='english'):\n",
        "    stop_words = set(stopwords.words(language))\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    return filtered_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e32fc79",
        "outputId": "a5d89909-4766-42db-903a-c5181cb00020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['mary', 'little', 'lamb', 'little', 'lamb', 'little', 'lamb', 'mary', 'little', 'lamb', 'fleece', 'white', 'snow', 'everywhere', 'mary', 'went', 'mary', 'went', 'mary', 'went', 'everywhere', 'mary', 'went', 'lamb', 'sure', 'go']\n"
          ]
        }
      ],
      "source": [
        "text_words_no_stopwords = remove_stopwords(text_words)\n",
        "print(text_words_no_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "collapsed": true,
        "id": "a5aa2c1a",
        "outputId": "318fd0c4-fda3-4860-c430-bdaf7d4048b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'everywhere': 0,\n",
              " 'fleece': 1,\n",
              " 'go': 2,\n",
              " 'lamb': 3,\n",
              " 'little': 4,\n",
              " 'mary': 5,\n",
              " 'snow': 6,\n",
              " 'sure': 7,\n",
              " 'went': 8,\n",
              " 'white': 9}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a set of unique words from the stopword-removed list\n",
        "unique_words_no_stopwords = sorted(list(set(text_words_no_stopwords)))\n",
        "\n",
        "# Create the new word-to-ID mapping\n",
        "word_to_id_no_stopwords = {word: i for i, word in enumerate(unique_words_no_stopwords)}\n",
        "\n",
        "display(word_to_id_no_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsxXYRiDu96L",
        "outputId": "75d4e10f-35eb-4b4a-8dc4-baea08b58b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus =nltk.sent_tokenize(text)\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aUNbv5k-vSwa",
        "outputId": "ee8399e0-abc9-421b-dce1-ca1f9a0ca89e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['mary',\n",
              "  'had',\n",
              "  'a',\n",
              "  'little',\n",
              "  'lamb',\n",
              "  'little',\n",
              "  'lamb',\n",
              "  'little',\n",
              "  'lamb',\n",
              "  'mary',\n",
              "  'had',\n",
              "  'a',\n",
              "  'little',\n",
              "  'lamb',\n",
              "  'its',\n",
              "  'fleece',\n",
              "  'was',\n",
              "  'white',\n",
              "  'as',\n",
              "  'snow'],\n",
              " ['and',\n",
              "  'everywhere',\n",
              "  'that',\n",
              "  'mary',\n",
              "  'went',\n",
              "  'mary',\n",
              "  'went',\n",
              "  'mary',\n",
              "  'went',\n",
              "  'everywhere',\n",
              "  'that',\n",
              "  'mary',\n",
              "  'went',\n",
              "  'the',\n",
              "  'lamb',\n",
              "  'was',\n",
              "  'sure',\n",
              "  'to',\n",
              "  'go']]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus=[tokenize(sentence,preserve_case=False) for sentence in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "collapsed": true,
        "id": "NpJHVUbYv3I5",
        "outputId": "16cebf7a-4c55-4dc9-b633-3a37fb198376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Samples', ylabel='Counts'>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "nlp=nltk.TextCollection(corpus)\n",
        "nlp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565f407f"
      },
      "source": [
        "# Task\n",
        "Calculate the TF-IDF for the text using the previously generated word-to-id mapping and the English stopword list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63547675"
      },
      "source": [
        "## Calculate term frequency (tf)\n",
        "\n",
        "### Subtask:\n",
        "Determine the frequency of each word in the text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb1a2a4"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the frequency of each word in the stopword-removed text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "collapsed": true,
        "id": "e3b7f1e7",
        "outputId": "48f1ee70-8afd-4182-fc9f-58ae239d7471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mary': 6,\n",
              " 'little': 4,\n",
              " 'lamb': 5,\n",
              " 'fleece': 1,\n",
              " 'white': 1,\n",
              " 'snow': 1,\n",
              " 'everywhere': 2,\n",
              " 'went': 4,\n",
              " 'sure': 1,\n",
              " 'go': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "term_frequency = {}\n",
        "for word in text_words_no_stopwords:\n",
        "  term_frequency[word] = term_frequency.get(word, 0) + 1\n",
        "\n",
        "display(term_frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43d632e1"
      },
      "source": [
        "## Calculate document frequency (df)\n",
        "\n",
        "### Subtask:\n",
        "Determine the number of documents (in this case, the single text) that contain each word.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ed98846"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a dictionary to store the document frequency and iterate through the unique words to set the document frequency to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "collapsed": true,
        "id": "f3ccc245",
        "outputId": "4c95084e-ce8b-40bf-a44f-8f4a1472d9de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'everywhere': 1,\n",
              " 'fleece': 1,\n",
              " 'go': 1,\n",
              " 'lamb': 1,\n",
              " 'little': 1,\n",
              " 'mary': 1,\n",
              " 'snow': 1,\n",
              " 'sure': 1,\n",
              " 'went': 1,\n",
              " 'white': 1}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "document_frequency = {}\n",
        "for word in unique_words_no_stopwords:\n",
        "  document_frequency[word] = 1\n",
        "\n",
        "display(document_frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68fcdfe7"
      },
      "source": [
        "## Calculate inverse document frequency (idf)\n",
        "\n",
        "### Subtask:\n",
        "Calculate the inverse document frequency for each word using the document frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c235635"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the inverse document frequency for each word using the document frequency and the total number of documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "8e25d71f",
        "outputId": "5e4b66a7-83bb-4ec5-e65a-0b8c90348f33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'everywhere': np.float64(0.0),\n",
              " 'fleece': np.float64(0.0),\n",
              " 'go': np.float64(0.0),\n",
              " 'lamb': np.float64(0.0),\n",
              " 'little': np.float64(0.0),\n",
              " 'mary': np.float64(0.0),\n",
              " 'snow': np.float64(0.0),\n",
              " 'sure': np.float64(0.0),\n",
              " 'went': np.float64(0.0),\n",
              " 'white': np.float64(0.0)}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "total_documents = 1\n",
        "inverse_document_frequency = {}\n",
        "\n",
        "for word, freq in document_frequency.items():\n",
        "  inverse_document_frequency[word] = np.log(total_documents / freq)\n",
        "\n",
        "display(inverse_document_frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be6688a8"
      },
      "source": [
        "## Calculate tf-idf\n",
        "\n",
        "### Subtask:\n",
        "Multiply the TF and IDF values for each word to get the TF-IDF score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b511f2e"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize an empty dictionary for TF-IDF scores, then iterate through the term frequencies and calculate the TF-IDF score for each word by multiplying its TF and IDF, storing the result in the dictionary, and finally displaying the dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "dcc9448a",
        "outputId": "4133bc13-499b-41cb-bbd9-e15f2ea1ac45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mary': np.float64(0.0),\n",
              " 'little': np.float64(0.0),\n",
              " 'lamb': np.float64(0.0),\n",
              " 'fleece': np.float64(0.0),\n",
              " 'white': np.float64(0.0),\n",
              " 'snow': np.float64(0.0),\n",
              " 'everywhere': np.float64(0.0),\n",
              " 'went': np.float64(0.0),\n",
              " 'sure': np.float64(0.0),\n",
              " 'go': np.float64(0.0)}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tf_idf_scores = {}\n",
        "\n",
        "for word, tf in term_frequency.items():\n",
        "    idf = inverse_document_frequency.get(word, 0)  # Get IDF, default to 0 if word not found\n",
        "    tf_idf = tf * idf\n",
        "    tf_idf_scores[word] = tf_idf\n",
        "\n",
        "display(tf_idf_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e818f5f9"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The frequency of each word in the preprocessed text was successfully calculated.\n",
        "*   The document frequency for each unique word was determined to be 1, as the analysis was performed on a single document.\n",
        "*   The inverse document frequency (IDF) for every word was calculated as 0, since each unique word appeared in the single document analyzed ($\\text{log}(1/1) = 0$).\n",
        "*   The TF-IDF score for each word was calculated by multiplying its term frequency and inverse document frequency. As the IDF for all words was 0, the resulting TF-IDF scores were also all 0.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The TF-IDF scores being all zero highlights that this metric is not informative when analyzing a single document, as it is designed to measure the importance of words across a collection of documents.\n",
        "*   To get meaningful TF-IDF scores, the analysis should be performed on a corpus containing multiple documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZneSlzMibM6c"
      },
      "source": [
        "### N-Grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaStBolIbL9C"
      },
      "outputs": [],
      "source": [
        "def get_ngrams(text,length):\n",
        "  from nltk import ngrams\n",
        "\n",
        "  n_grams=ngrams(tokenize(text),length)\n",
        "  return [ ' '.join(grams) for grams in n_grams]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OAuURM4v4kcS",
        "outputId": "add74f0f-aefb-4fa8-8be4-683cf8ca5169"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mary had',\n",
              " 'had a',\n",
              " 'a little',\n",
              " 'little lamb',\n",
              " 'lamb little',\n",
              " 'little lamb',\n",
              " 'lamb little',\n",
              " 'little lamb',\n",
              " 'lamb mary',\n",
              " 'mary had',\n",
              " 'had a',\n",
              " 'a little',\n",
              " 'little lamb',\n",
              " 'lamb its',\n",
              " 'its fleece',\n",
              " 'fleece was',\n",
              " 'was white',\n",
              " 'white as',\n",
              " 'as snow',\n",
              " 'snow and',\n",
              " 'and everywhere',\n",
              " 'everywhere that',\n",
              " 'that mary',\n",
              " 'mary went',\n",
              " 'went mary',\n",
              " 'mary went',\n",
              " 'went mary',\n",
              " 'mary went',\n",
              " 'went everywhere',\n",
              " 'everywhere that',\n",
              " 'that mary',\n",
              " 'mary went',\n",
              " 'went the',\n",
              " 'the lamb',\n",
              " 'lamb was',\n",
              " 'was sure',\n",
              " 'sure to',\n",
              " 'to go']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_ngrams(text.lower(),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHJqjQ456DAF"
      },
      "source": [
        " Definition:\n",
        "Collocations are words that co-occur together unusually often, more than by random chance.\n",
        "\n",
        "Example: \"strong tea\", \"make a decision\", \"New York\"\n",
        "\n",
        "Even though \"strong coffee\" and \"powerful computer\" make sense, \"powerful tea\" feels wrong  thats why \"strong tea\" is a collocation.\n",
        "\n",
        " In NLP\n",
        "\n",
        "We usually detect collocations using statistical association measures like:\n",
        "\n",
        "Pointwise Mutual Information (PMI)\n",
        "\n",
        "Chi-square test\n",
        "\n",
        "t-test\n",
        "\n",
        "Likelihood ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tahoJOle596e"
      },
      "outputs": [],
      "source": [
        "from nltk.collocations import BigramCollocationFinder,BigramAssocMeasures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "46a7dLDeBFIz",
        "outputId": "8f4b6374-dc9e-4e43-9450-d2e243c427ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('little', 'lamb'), 20.789064969512463),\n",
              " (('mary', 'went'), 18.154919185356587),\n",
              " (('everywhere', 'that'), 15.777294140200038),\n",
              " (('had', 'a'), 15.777294140200038),\n",
              " (('a', 'little'), 10.232116695720478),\n",
              " (('as', 'snow'), 9.301260258907092),\n",
              " (('its', 'fleece'), 9.301260258907092),\n",
              " (('snow', 'and'), 9.301260258907092),\n",
              " (('sure', 'to'), 9.301260258907092),\n",
              " (('to', 'go'), 9.301260258907092),\n",
              " (('white', 'as'), 9.301260258907092),\n",
              " (('mary', 'had'), 8.139124120662284),\n",
              " (('that', 'mary'), 8.139124120662284),\n",
              " (('and', 'everywhere'), 6.528671536667327),\n",
              " (('fleece', 'was'), 6.528671536667327),\n",
              " (('was', 'sure'), 6.528671536667327),\n",
              " (('was', 'white'), 6.528671536667327),\n",
              " (('went', 'the'), 4.802579101956642),\n",
              " (('lamb', 'its'), 4.297236023525216),\n",
              " (('the', 'lamb'), 4.297236023525216),\n",
              " (('lamb', 'little'), 3.850143362325084),\n",
              " (('went', 'mary'), 3.065215528887738),\n",
              " (('went', 'everywhere'), 2.196764352889584),\n",
              " (('lamb', 'was'), 1.7502532877068806),\n",
              " (('lamb', 'mary'), 0.08819306486371048)]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram =BigramCollocationFinder.from_words(tokenize(text,False))\n",
        "scored=bigram.score_ngrams(BigramAssocMeasures.likelihood_ratio)\n",
        "scored\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtWCMcfrEJZT"
      },
      "source": [
        "### WORD EMBEDDINGS\n",
        "\n",
        "What are Word Embeddings?\n",
        "\n",
        "Word embeddings are vector representations of words in a continuous vector space.\n",
        "\n",
        "Unlike one-hot encoding (which is sparse and doesnt capture meaning), embeddings place semantically similar words closer together in the space.\n",
        "\n",
        " Example:\n",
        "\n",
        "\"king\" and \"queen\" will have vectors that are close.\n",
        "\n",
        "\"dog\" and \"cat\" will also cluster together.\n",
        "\n",
        "\"king - man + woman  queen\" (famous word analogy example).\n",
        "\n",
        " Why Use Them?\n",
        "\n",
        "Capture semantic meaning and context of words.\n",
        "\n",
        "Reduce dimensionality compared to one-hot (millions  few hundred).\n",
        "\n",
        "Enable ML models to understand similarity, analogy, sentiment, etc.\n",
        "\n",
        " Common Word Embedding Models\n",
        "\n",
        "Word2Vec (Google, 2013)\n",
        "\n",
        "Skip-gram & CBOW models.\n",
        "\n",
        "Learns embeddings by predicting context words.\n",
        "\n",
        "GloVe (Stanford, 2014)\n",
        "\n",
        "Global vectors for word representation.\n",
        "\n",
        "Based on co-occurrence statistics of words.\n",
        "\n",
        "FastText (Facebook, 2016)\n",
        "\n",
        "Extends Word2Vec.\n",
        "\n",
        "Breaks words into subword n-grams (handles out-of-vocabulary words).\n",
        "\n",
        "ELMo, BERT, GPT, etc. (Contextual Embeddings)\n",
        "\n",
        "Deep neural networks (transformers, LSTMs).\n",
        "\n",
        "Word meaning changes with context:\n",
        "\n",
        "bank (river bank) vs bank (financial institution).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX11cpCaI4CL",
        "outputId": "a98194a5-dd6d-49ed-f8c5-191e9778e08d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JOXbXz45FNgP",
        "outputId": "383640c2-8d47-488a-da3c-107700eb389b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'language': [-1.0725874e-03  4.7292133e-04  1.0207964e-02  1.8020779e-02\n",
            " -1.8608205e-02 -1.4235382e-02  1.2919346e-02  1.7948203e-02\n",
            " -1.0032100e-02 -7.5276764e-03  1.4762839e-02 -3.0673228e-03\n",
            " -9.0743508e-03  1.3109728e-02 -9.7215259e-03 -3.6324856e-03\n",
            "  5.7538725e-03  1.9839935e-03 -1.6572483e-02 -1.8899979e-02\n",
            "  1.4625344e-02  1.0141781e-02  1.3517062e-02  1.5259202e-03\n",
            "  1.2703355e-02 -6.8115760e-03 -1.8930373e-03  1.1538576e-02\n",
            " -1.5045141e-02 -7.8731822e-03 -1.5025027e-02 -1.8603150e-03\n",
            "  1.9078601e-02 -1.4640148e-02 -4.6681156e-03 -3.8759627e-03\n",
            "  1.6156876e-02 -1.1863262e-02  9.0336078e-05 -9.5086470e-03\n",
            " -1.9209482e-02  1.0015828e-02 -1.7521342e-02 -8.7847402e-03\n",
            " -7.0208669e-05 -5.9243635e-04 -1.5324379e-02  1.9231869e-02\n",
            "  9.9653518e-03  1.8468576e-02]\n",
            "Most similar to 'language': [('understand', 0.1267007291316986), ('human', 0.04237300157546997), ('processing', 0.012442180886864662), ('machines', -0.0144752636551857), ('natural', -0.05974649265408516), ('makes', -0.11821284145116806)]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural language processing makes machines understand human language\"\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec([tokens], vector_size=50, window=3, min_count=1, sg=1)\n",
        "\n",
        "# Get embedding vector\n",
        "vector = model.wv['language']\n",
        "print(\"Vector for 'language':\", vector)\n",
        "\n",
        "# Similar words\n",
        "print(\"Most similar to 'language':\", model.wv.most_similar('language'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U67zgiCJ3qU"
      },
      "source": [
        "LEMMATIZATION AND STEMMING\n",
        "\n",
        " Stemming\n",
        "\n",
        "What it does: Cuts off word endings to reduce words to their root form.\n",
        "\n",
        "How: Uses crude heuristic rules (e.g., remove -ing, -ed, -s).\n",
        "\n",
        "Result: Sometimes not a valid word.\n",
        "\n",
        " Example:\n",
        "\n",
        "running  run\n",
        "\n",
        "flies  fli\n",
        "\n",
        "better  better (no rule applied, might miss some cases)\n",
        "\n",
        " Stemming is fast but not always accurate.\n",
        "\n",
        " Lemmatization\n",
        "\n",
        "What it does: Reduces words to their dictionary/base form (lemma).\n",
        "\n",
        "How: Uses vocabulary + morphology (needs to know the part of speech).\n",
        "\n",
        "Result: Always produces valid words.\n",
        "\n",
        " Example:\n",
        "\n",
        "running  run\n",
        "\n",
        "flies  fly\n",
        "\n",
        "better  good (semantic lemmatization, requires context)\n",
        "\n",
        " Lemmatization is slower but more accurate.\n",
        "\n",
        " Main Difference\n",
        "\n",
        "Stemming = chop endings, might produce nonsense (studies  studi).\n",
        "\n",
        "Lemmatization = smart reduction using language rules (studies  study).\n",
        "\n",
        " In NLP tasks:\n",
        "\n",
        "Stemming is often used for speed (e.g., search engines).\n",
        "\n",
        "Lemmatization is used when accuracy matters (e.g., chatbot, sentiment analysis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lS8iFPmFMSc-",
        "outputId": "b3e24eb1-ce33-48fd-d8c4-0290edbbc3c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"comparison\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"porterStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"love\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lancasterStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"lov\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snowballStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"love\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"regexpStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"loved\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "comparison"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3d4929ea-3348-4fa9-80eb-b2459df82fbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>porterStemmer</th>\n",
              "      <th>lancasterStemmer</th>\n",
              "      <th>snowballStemmer</th>\n",
              "      <th>regexpStemmer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>playing</th>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loved</th>\n",
              "      <td>love</td>\n",
              "      <td>lov</td>\n",
              "      <td>love</td>\n",
              "      <td>loved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ran</th>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>river</th>\n",
              "      <td>river</td>\n",
              "      <td>riv</td>\n",
              "      <td>river</td>\n",
              "      <td>river</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>friendships</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>misunderstanding</th>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trouble</th>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>troubling</th>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d4929ea-3348-4fa9-80eb-b2459df82fbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d4929ea-3348-4fa9-80eb-b2459df82fbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d4929ea-3348-4fa9-80eb-b2459df82fbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a6673e25-4707-4f81-b3fe-b05305c866aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6673e25-4707-4f81-b3fe-b05305c866aa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a6673e25-4707-4f81-b3fe-b05305c866aa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_877db1c7-08a1-4849-9216-57f3ed77284f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_877db1c7-08a1-4849-9216-57f3ed77284f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  porterStemmer lancasterStemmer snowballStemmer  \\\n",
              "playing                    play             play            play   \n",
              "loved                      love              lov            love   \n",
              "ran                         ran              ran             ran   \n",
              "river                     river              riv           river   \n",
              "friendships          friendship           friend      friendship   \n",
              "misunderstanding  misunderstand    misunderstand   misunderstand   \n",
              "trouble                  troubl           troubl          troubl   \n",
              "troubling                troubl           troubl          troubl   \n",
              "\n",
              "                  regexpStemmer  \n",
              "playing                    play  \n",
              "loved                     loved  \n",
              "ran                         ran  \n",
              "river                     river  \n",
              "friendships          friendship  \n",
              "misunderstanding  misunderstand  \n",
              "trouble                  troubl  \n",
              "troubling                troubl  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  TEXT CLEANING DEMO\n",
        "import re\n",
        "\n",
        "words=['playing','loved','ran','river','friendships','misunderstanding','trouble','troubling']\n",
        "\n",
        "stemmers={\n",
        "    'porterStemmer':nltk.PorterStemmer(),\n",
        "    'lancasterStemmer':nltk.LancasterStemmer(),\n",
        "    'snowballStemmer':nltk.SnowballStemmer('english'),\n",
        "    'regexpStemmer':nltk.RegexpStemmer('ing$|s$|e$|able$')\n",
        "}\n",
        "\n",
        "matrix=[]\n",
        "for word in words:\n",
        "  row=[]\n",
        "  for stemmer in stemmers:\n",
        "    stem=stemmers[stemmer]\n",
        "    row.append(stem.stem(word))\n",
        "  matrix.append(row)\n",
        "\n",
        "comparison=pd.DataFrame(matrix,index=words,columns=stemmers.keys())\n",
        "\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAd2aFCkRRgM",
        "outputId": "39eeed2b-612a-4ac9-f149-382bb9e4d51f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "collapsed": true,
        "id": "bjnYtbNfPkPM",
        "outputId": "a8d2634f-b7d0-4d15-cbcf-57fe2aa8c7f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"comparison\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"porterStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"love\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lancasterStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"lov\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"snowballStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"love\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"regexpStemmer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"loved\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wordnet noun\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"loved\",\n          \"misunderstanding\",\n          \"playing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wordnet verb\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"play\",\n          \"love\",\n          \"misunderstand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "comparison"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29877f8a-6a9f-4ac6-853c-55fb31970732\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>porterStemmer</th>\n",
              "      <th>lancasterStemmer</th>\n",
              "      <th>snowballStemmer</th>\n",
              "      <th>regexpStemmer</th>\n",
              "      <th>wordnet noun</th>\n",
              "      <th>wordnet verb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>playing</th>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "      <td>playing</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loved</th>\n",
              "      <td>love</td>\n",
              "      <td>lov</td>\n",
              "      <td>love</td>\n",
              "      <td>loved</td>\n",
              "      <td>loved</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ran</th>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>river</th>\n",
              "      <td>river</td>\n",
              "      <td>riv</td>\n",
              "      <td>river</td>\n",
              "      <td>river</td>\n",
              "      <td>river</td>\n",
              "      <td>river</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>friendships</th>\n",
              "      <td>friendship</td>\n",
              "      <td>friend</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendship</td>\n",
              "      <td>friendships</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>misunderstanding</th>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstand</td>\n",
              "      <td>misunderstanding</td>\n",
              "      <td>misunderstand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trouble</th>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>trouble</td>\n",
              "      <td>trouble</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>troubling</th>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubl</td>\n",
              "      <td>troubling</td>\n",
              "      <td>trouble</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29877f8a-6a9f-4ac6-853c-55fb31970732')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29877f8a-6a9f-4ac6-853c-55fb31970732 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29877f8a-6a9f-4ac6-853c-55fb31970732');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-36997a6b-d392-4a0f-ae9d-f17c439c470a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36997a6b-d392-4a0f-ae9d-f17c439c470a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-36997a6b-d392-4a0f-ae9d-f17c439c470a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_83b3a17f-68c5-4d2f-a07f-519546acdd06\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_83b3a17f-68c5-4d2f-a07f-519546acdd06 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                  porterStemmer lancasterStemmer snowballStemmer  \\\n",
              "playing                    play             play            play   \n",
              "loved                      love              lov            love   \n",
              "ran                         ran              ran             ran   \n",
              "river                     river              riv           river   \n",
              "friendships          friendship           friend      friendship   \n",
              "misunderstanding  misunderstand    misunderstand   misunderstand   \n",
              "trouble                  troubl           troubl          troubl   \n",
              "troubling                troubl           troubl          troubl   \n",
              "\n",
              "                  regexpStemmer      wordnet noun   wordnet verb  \n",
              "playing                    play           playing           play  \n",
              "loved                     loved             loved           love  \n",
              "ran                         ran               ran            run  \n",
              "river                     river             river          river  \n",
              "friendships          friendship        friendship    friendships  \n",
              "misunderstanding  misunderstand  misunderstanding  misunderstand  \n",
              "trouble                  troubl           trouble        trouble  \n",
              "troubling                troubl         troubling        trouble  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Lemmatization\n",
        "\n",
        "wordnet=nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "results_n =[wordnet.lemmatize(word,'n') for word in words]\n",
        "results_v =[wordnet.lemmatize(word,'v') for word in words]\n",
        "\n",
        "comparison['wordnet noun']=results_n\n",
        "comparison['wordnet verb']=results_v\n",
        "\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbjiPtbWT0Ti"
      },
      "source": [
        "Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayEpR-4kVCeH",
        "outputId": "b67eef88-390f-4df1-a5ba-ff5880b6fefc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('tagsets')\n",
        "nltk.download('tagsets_json')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jsluu5cTRkai",
        "outputId": "bc634507-cba7-46c5-bcf3-6c5ab226a502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ],
      "source": [
        "nltk.help.upenn_tagset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP2X-FyeXMCw"
      },
      "source": [
        "**Chunking**\n",
        "\n",
        " Chunking (sometimes called shallow parsing) is the process of grouping words into meaningful phrases or \"chunks,\" usually based on their part-of-speech (POS) tags.\n",
        "\n",
        " Think of it as going one step above POS tagging:\n",
        "\n",
        "POS tagging tells you each words role (noun, verb, adjective, etc.).\n",
        "\n",
        "Chunking groups those words into higher-level units like noun phrases (NP), verb phrases (VP), or prepositional phrases (PP).\n",
        "\n",
        "Why its useful:\n",
        "\n",
        "Information extraction  grab entities like names, dates, locations.\n",
        "\n",
        "Question answering  identify subjects, objects, predicates.\n",
        "\n",
        "Text summarization  detect key phrases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLjetZu4Xduf",
        "outputId": "efb14d5b-7e9d-48ec-c393-0fa31b5a6de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             S                              \n",
            "     ________|________                       \n",
            "    |                 NP                    \n",
            "    |         ________|_________________     \n",
            "barked/VBD the/DT little/JJ yellow/JJ dog/NN\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\")]\n",
        "\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(sentence)\n",
        "\n",
        "# Print the tree structure\n",
        "result.pretty_print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "HNl1uyaSYHKH",
        "outputId": "f9763143-f83a-4ed7-f5b5-1ec1c37eebb5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import Tree\n",
        "\n",
        "# Example sentence with POS tags\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\")]\n",
        "\n",
        "# Define chunk grammar\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "\n",
        "# Parse\n",
        "result = cp.parse(sentence)\n",
        "\n",
        "# Function to recursively draw tree with matplotlib\n",
        "def draw_nltk_tree(tree, ax, x=0, y=0, level_gap=1.5, x_gap=1):\n",
        "    if isinstance(tree, Tree):\n",
        "        label = tree.label()\n",
        "        ax.text(x, y, label, ha='center', va='center',\n",
        "                bbox=dict(facecolor='lightblue', edgecolor='black'))\n",
        "        num_children = len(tree)\n",
        "        width = (num_children - 1) * x_gap if num_children > 1 else 0\n",
        "        start_x = x - width / 2\n",
        "        for i, child in enumerate(tree):\n",
        "            child_x = start_x + i * x_gap\n",
        "            child_y = y - level_gap\n",
        "            ax.plot([x, child_x], [y-0.1, child_y+0.4], color=\"black\")\n",
        "            draw_nltk_tree(child, ax, child_x, child_y, level_gap, x_gap)\n",
        "    else:\n",
        "        ax.text(x, y, tree, ha='center', va='center',\n",
        "                bbox=dict(facecolor='lightgreen', edgecolor='black'))\n",
        "\n",
        "# Plot the tree\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.axis('off')\n",
        "draw_nltk_tree(result, ax, x=0, y=0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6WS0DlP5Snv"
      },
      "source": [
        "LESSON 3: DEMO NAMED ENTITY RECOGNITION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42pHpOum5npY"
      },
      "outputs": [],
      "source": [
        "text = \"They refuse to permit us to obatain the refuse permit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lQujBqrT5-HI",
        "outputId": "364b256d-bf7c-42ac-cf40-d8739b0b316a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['They',\n",
              " 'refuse',\n",
              " 'to',\n",
              " 'permit',\n",
              " 'us',\n",
              " 'to',\n",
              " 'obatain',\n",
              " 'the',\n",
              " 'refuse',\n",
              " 'permit']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens_sample_one=nltk.word_tokenize(text)\n",
        "tokens_sample_one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5347c0ea",
        "outputId": "d2f668e3-26ce-478c-abfd-8ddd482fc02b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "0tLsBHkK6JqN",
        "outputId": "636029cf-4a03-4cce-926f-328258dc4e60"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-183603967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_sample_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load, lang)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tagdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mload_from_json\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Automatically find path to the tagger if location is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"taggers/averaged_perceptron_tagger_{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTAGGER_JSONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "tags=nltk.pos_tag(tokens_sample_one)\n",
        "tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ddcaI8mQWcw"
      },
      "source": [
        "**TOPIC MODELLING TECHNIQUES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHV3txyZVGSb"
      },
      "source": [
        " What is a Term-Document Matrix?\n",
        "\n",
        "A Term-Document Matrix (TDM) is a table that represents the frequency of terms (words) across a collection of documents.\n",
        "\n",
        "Rows  unique terms (words) in the corpus\n",
        "\n",
        "Columns  documents\n",
        "\n",
        "Entries  counts (or weights, e.g., TF or TF-IDF) showing how many times a term appears in a document\n",
        "\n",
        " Example\n",
        "\n",
        "Suppose we have 3 documents:\n",
        "\n",
        "Doc1: \"AI is the future of data\"\n",
        "\n",
        "Doc2: \"AI and data drive innovation\"\n",
        "\n",
        "Doc3: \"Models learn from data\"\n",
        "\n",
        "First, collect the unique terms:\n",
        "[AI, is, the, future, of, data, and, drive, innovation, models, learn, from]\n",
        "\n",
        "Now build the matrix:\n",
        "\n",
        "Term\tDoc1\tDoc2\tDoc3\n",
        "AI\t1\t1\t0\n",
        "is\t1\t0\t0\n",
        "the\t1\t0\t0\n",
        "future\t1\t0\t0\n",
        "of\t1\t0\t0\n",
        "data\t1\t1\t1\n",
        "and\t0\t1\t0\n",
        "drive\t0\t1\t0\n",
        "innovation\t0\t1\t0\n",
        "models\t0\t0\t1\n",
        "learn\t0\t0\t1\n",
        "from\t0\t0\t1\n",
        "\n",
        "\n",
        "Variants\n",
        "\n",
        "Raw counts (like above)\n",
        "\n",
        "TF (Term Frequency): normalized counts\n",
        "\n",
        "TF-IDF (Term Frequency  Inverse Document Frequency): balances frequent vs. rare words\n",
        "\n",
        " Usage:\n",
        "\n",
        "Text mining\n",
        "\n",
        "Document similarity (cosine similarity)\n",
        "\n",
        "Search engines\n",
        "\n",
        "Topic modeling (e.g., LSA, LDA)\n",
        "\n",
        "\n",
        "\n",
        "Explicit Semantic Analysis\n",
        "\n",
        "\n",
        " What is Explicit Semantic Analysis (ESA)?\n",
        "\n",
        "Explicit Semantic Analysis (ESA) is a method for representing the meaning of text by mapping it into a high-dimensional space of concepts derived from a large knowledge base (e.g., Wikipedia).\n",
        "\n",
        "It was introduced by Gabrilovich & Markovitch (2007) as an alternative to Latent Semantic Analysis (LSA).\n",
        "\n",
        " Core Idea\n",
        "\n",
        "Instead of just using words or latent vectors, ESA represents text as a weighted vector of concepts.\n",
        "\n",
        "Each concept corresponds to a Wikipedia article (or another structured knowledge base entry).\n",
        "\n",
        "The weight of a concept reflects how strongly the text relates to that Wikipedia article.\n",
        "\n",
        " Example\n",
        "\n",
        "Suppose the input text is:\n",
        "\n",
        "Apple is a technology company that makes iPhones and MacBooks.\n",
        "\n",
        "Using ESA with Wikipedia as the knowledge base, it may map to concepts like:\n",
        "\n",
        "Apple Inc.  0.87\n",
        "\n",
        "iPhone  0.72\n",
        "\n",
        "MacBook  0.69\n",
        "\n",
        "Steve Jobs  0.55\n",
        "\n",
        "Technology companies  0.51\n",
        "\n",
        "Apple (fruit)  0.05 (very low weight, since not the right context)\n",
        "\n",
        "So instead of a bag of words, you get a bag of concepts.\n",
        "\n",
        " Why is ESA useful?\n",
        "\n",
        "Handles synonymy: cellphone and mobile phone map to the same Wikipedia concept.\n",
        "\n",
        "Handles polysemy: Apple is disambiguated based on context (fruit vs. company).\n",
        "\n",
        "Provides semantic similarity between texts, even if they dont share the same words.\n",
        "\n",
        " Applications\n",
        "\n",
        "Document clustering & classification\n",
        "\n",
        "Semantic search\n",
        "\n",
        "Measuring text similarity\n",
        "\n",
        "Question answering\n",
        "\n",
        "Knowledge-based NLP tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG3GpVQ7VBjv"
      },
      "source": [
        "LATENT SEMANTIC ANALYSIS\n",
        "\n",
        "Latent Semantic Analysis (LSA)  also known as Latent Semantic Indexing (LSI) when used in search engines  is a natural language processing (NLP) technique that helps computers understand the relationships between words and their meanings in a collection of documents.\n",
        "\n",
        "Lets break it down in a simple, engineer-friendly way\n",
        "\n",
        " The Core Idea\n",
        "\n",
        "Words that appear in similar contexts tend to have similar meanings.\n",
        "For example:\n",
        "\n",
        "bank and loan often appear together in finance-related documents.\n",
        "\n",
        "river and bank appear together in geography-related texts.\n",
        "\n",
        "LSA tries to uncover these hidden (latent) relationships between words and documents.\n",
        "\n",
        " How It Works (under the hood)\n",
        "\n",
        "Build a term-document matrix\n",
        "\n",
        "Each row = a unique word (term)\n",
        "\n",
        "Each column = a document\n",
        "\n",
        "Each cell = how many times a word appears in that document\n",
        "\n",
        "bank loan money river\n",
        "D1   3    5    0    0\n",
        "D2   0    0    0    4\n",
        "D3   2    4    1    0\n",
        "\n",
        "Apply Singular Value Decomposition (SVD)\n",
        "LSA then decomposes the matrix into 3 smaller ones:\n",
        "\n",
        "A = U    V\n",
        "\n",
        "U represents words and their relationships to concepts\n",
        "\n",
        " contains the importance (weights) of those concepts\n",
        "\n",
        "V links documents to those same concepts\n",
        "\n",
        "Reduce dimensionality\n",
        "By keeping only the top k singular values (largest in ), LSA removes noise and keeps the most important patterns  similar to how PCA (Principal Component Analysis) works.\n",
        "\n",
        " The Outcome\n",
        "\n",
        "Now words and documents are represented in a semantic space, where:\n",
        "\n",
        "Similar words are closer together, even if they dont literally appear together.\n",
        "\n",
        "You can compute document similarity, keyword clustering, or topic discovery more intelligently.\n",
        "\n",
        " Real-world Uses\n",
        "\n",
        " Search engines: Match queries with semantically related documents.\n",
        "\n",
        " Document classification: Group similar texts or detect topics.\n",
        "\n",
        " Chatbots: Enhance understanding of user input beyond literal words.\n",
        "\n",
        " In short:\n",
        "\n",
        "LSA helps computers see the meaning behind the words  like giving your search algorithm a bit of common sense.\n",
        "It worth noting that LSA is linear algebra based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Lt-GXNjxU3JH",
        "outputId": "4f7623e0-dc05-4208-b457-117854b6008d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Document representation in semantic space:\n",
            "   Concept 1  Concept 2                                           Document\n",
            "0   0.721243  -0.344956     The bank approved the loan for the new project\n",
            "1   0.560871   0.522524                  He went fishing by the river bank\n",
            "2   0.665621  -0.229293  The project received financial support from th...\n",
            "3   0.264801   0.748428                  She loves kayaking near the river\n",
            "4   0.248820  -0.361039   The company took a big loan to expand operations\n",
            "\n",
            " Concept 1 top terms:\n",
            "  bank            0.4844\n",
            "  project         0.4013\n",
            "  loan            0.2730\n",
            "  new             0.2642\n",
            "  approved        0.2642\n",
            "\n",
            " Concept 2 top terms:\n",
            "  river           0.4894\n",
            "  kayaking        0.3451\n",
            "  loves           0.3451\n",
            "  near            0.3451\n",
            "  went            0.2615\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a tiny corpus\n",
        "documents = [\n",
        "    \"The bank approved the loan for the new project\",\n",
        "    \"He went fishing by the river bank\",\n",
        "    \"The project received financial support from the bank\",\n",
        "    \"She loves kayaking near the river\",\n",
        "    \"The company took a big loan to expand operations\"\n",
        "]\n",
        "\n",
        "# Step 2: Convert text to TFIDF features\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Step 3: Apply LSA using Truncated SVD (reduce to 2 latent topics)\n",
        "lsa = TruncatedSVD(n_components=2, random_state=42)\n",
        "X_lsa = lsa.fit_transform(X)\n",
        "\n",
        "# Step 4: Create DataFrame to visualize\n",
        "lsa_df = pd.DataFrame(X_lsa, columns=[\"Concept 1\", \"Concept 2\"])\n",
        "lsa_df[\"Document\"] = documents\n",
        "\n",
        "print(\"\\n Document representation in semantic space:\")\n",
        "print(lsa_df)\n",
        "\n",
        "# Step 5 (optional): Show top words that define each latent concept\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "for i, comp in enumerate(lsa.components_):\n",
        "    terms_in_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_in_comp, key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"\\n Concept {i+1} top terms:\")\n",
        "    for term, weight in sorted_terms:\n",
        "        print(f\"  {term:<15} {weight:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x1kRNgeGYaBW",
        "outputId": "55148996-690d-48fd-d45a-53fe157f3ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " LSA Document Representation:\n",
            "   Concept 1  Concept 2                                           Document\n",
            "0   0.721243  -0.344956     The bank approved the loan for the new project\n",
            "1   0.560871   0.522524                  He went fishing by the river bank\n",
            "2   0.665621  -0.229293  The project received financial support from th...\n",
            "3   0.264801   0.748428                  She loves kayaking near the river\n",
            "4   0.248820  -0.361039   The company took a big loan to expand operations\n",
            "\n",
            " Top Terms per Latent Concept:\n",
            "\n",
            "Concept 1:\n",
            "  bank            0.4844\n",
            "  project         0.4013\n",
            "  loan            0.2730\n",
            "  new             0.2642\n",
            "  approved        0.2642\n",
            "\n",
            "Concept 2:\n",
            "  river           0.4894\n",
            "  kayaking        0.3451\n",
            "  loves           0.3451\n",
            "  near            0.3451\n",
            "  went            0.2615\n"
          ]
        }
      ],
      "source": [
        "# Full LSA Pipeline using scikit-learn\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Example corpus\n",
        "documents = [\n",
        "    \"The bank approved the loan for the new project\",\n",
        "    \"He went fishing by the river bank\",\n",
        "    \"The project received financial support from the bank\",\n",
        "    \"She loves kayaking near the river\",\n",
        "    \"The company took a big loan to expand operations\"\n",
        "]\n",
        "\n",
        "# Step 2: Build an LSA pipeline\n",
        "lsa_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('svd', TruncatedSVD(n_components=2, random_state=42))\n",
        "])\n",
        "\n",
        "# Step 3: Fit and transform the data\n",
        "X_lsa = lsa_pipeline.fit_transform(documents)\n",
        "\n",
        "# Step 4: Create DataFrame for visualization\n",
        "lsa_df = pd.DataFrame(X_lsa, columns=[\"Concept 1\", \"Concept 2\"])\n",
        "lsa_df[\"Document\"] = documents\n",
        "\n",
        "print(\"\\n LSA Document Representation:\")\n",
        "print(lsa_df)\n",
        "\n",
        "# Step 5: Inspect the top terms in each concept\n",
        "vectorizer = lsa_pipeline.named_steps['tfidf']\n",
        "svd = lsa_pipeline.named_steps['svd']\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"\\n Top Terms per Latent Concept:\")\n",
        "for i, comp in enumerate(svd.components_):\n",
        "    sorted_terms = sorted(zip(terms, comp), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"\\nConcept {i+1}:\")\n",
        "    for term, weight in sorted_terms:\n",
        "        print(f\"  {term:<15} {weight:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VOr1suIZJHd",
        "outputId": "947bbb7d-512c-46d8-c0dd-cbb69fff1039"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lsa_model.pkl']"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(lsa_pipeline, \"lsa_model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozVCPj3HW0JE"
      },
      "source": [
        "Latent Dirichlet Allocation (Probablillistic topic modelling )\n",
        "\n",
        " What is Latent Dirichlet Allocation (LDA)?\n",
        "\n",
        "Latent Dirichlet Allocation is a generative probabilistic model that assumes:\n",
        "\n",
        "Each document is a mixture of topics.\n",
        "\n",
        "Each topic is a distribution over words.\n",
        "\n",
        "So instead of purely finding patterns in term frequencies (like LSA), LDA models the process that could have generated the documents.\n",
        "\n",
        " Intuition\n",
        "\n",
        "Think of it this way:\n",
        "\n",
        "If a document talks mostly about \"finance\" and a bit about \"sports\", LDA will infer that proportion  e.g. 80% topic 1 (finance), 20% topic 2 (sports)  automatically from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acJ2Sfysa6eG",
        "outputId": "9c47a454-c54f-453f-ba6b-bca08dbe7761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Topic 1:\n",
            "loan, operations, took, big, expand\n",
            "\n",
            " Topic 2:\n",
            "bank, river, project, near, loves\n",
            "\n",
            " Document Topic Distribution:\n",
            "    Topic 1   Topic 2                                           Document\n",
            "0  0.890848  0.109152     The bank approved the loan for the new project\n",
            "1  0.107652  0.892348                  He went fishing by the river bank\n",
            "2  0.097157  0.902843  The project received financial support from th...\n",
            "3  0.104214  0.895786                  She loves kayaking near the river\n",
            "4  0.926062  0.073938   The company took a big loan to expand operations\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Example corpus\n",
        "documents = [\n",
        "    \"The bank approved the loan for the new project\",\n",
        "    \"He went fishing by the river bank\",\n",
        "    \"The project received financial support from the bank\",\n",
        "    \"She loves kayaking near the river\",\n",
        "    \"The company took a big loan to expand operations\"\n",
        "]\n",
        "\n",
        "# Step 2: Build an LDA pipeline\n",
        "lda_pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
        "    ('lda', LatentDirichletAllocation(n_components=2, random_state=42))\n",
        "])\n",
        "\n",
        "# Step 3: Fit the model\n",
        "lda_pipeline.fit(documents)\n",
        "\n",
        "# Step 4: Access components\n",
        "vectorizer = lda_pipeline.named_steps['vectorizer']\n",
        "lda_model = lda_pipeline.named_steps['lda']\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Step 5: Show topics and top words\n",
        "for idx, topic in enumerate(lda_model.components_):\n",
        "    print(f\"\\n Topic {idx + 1}:\")\n",
        "    sorted_terms = topic.argsort()[::-1][:5]\n",
        "    print(\", \".join(terms[i] for i in sorted_terms))\n",
        "\n",
        "# Step 6: Show document-topic distributions\n",
        "doc_topics = lda_model.transform(vectorizer.transform(documents))\n",
        "df = pd.DataFrame(doc_topics, columns=[\"Topic 1\", \"Topic 2\"])\n",
        "df[\"Document\"] = documents\n",
        "\n",
        "print(\"\\n Document Topic Distribution:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjh3jOrNbiBW"
      },
      "source": [
        " Key Differences from LSA\n",
        "Feature\tLSA\tLDA\n",
        "Based on\tLinear algebra (SVD)\tProbabilistic generative model\n",
        "Uses\tTF-IDF\tCount (term frequency)\n",
        "Topics are\tOrthogonal (geometric)\tDistributions (probabilities)\n",
        "Output\tConcept embeddings\tTopic-word & doc-topic distributions\n",
        "Interpretability\tLower\tHigher (topics make sense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRSSGxXXfjD6"
      },
      "source": [
        "### **Sentiment Analysis**\n",
        "\n",
        "Sentiment Analysis quantifies the emotional polarity of text:\n",
        "\n",
        "Is the text positive, negative, or neutral  and how strong is that feeling?\n",
        "\n",
        "Example:\n",
        "\n",
        "Sentence\tSentiment\n",
        "I love this product!\t Positive\n",
        "This product is not good.\t Negative\n",
        "Its okay, I guess.\t Neutral\n",
        "\n",
        " Quantifying Words & Feelings\n",
        "\n",
        "You can quantify words using:\n",
        "\n",
        "Lexicons  prebuilt word sentiment dictionaries (e.g., AFINN, VADER, TextBlob).\n",
        "\n",
        "Machine Learning  learn sentiment weights from labeled data.\n",
        "\n",
        "Embeddings / Transformers  contextual understanding via deep learning.\n",
        "\n",
        "\n",
        "Sentiment Analysis (SA)  also known as opinion mining  is a branch of Natural Language Processing (NLP) that focuses on identifying emotions, opinions, or attitudes expressed in text.\n",
        "Its how machines learn to detect if a tweet is angry , a review is positive , or a comment is neutral .\n",
        "\n",
        "2. Core Concepts\n",
        " Word Counting\n",
        "\n",
        "Word counting is the foundation of text analysis.\n",
        "We convert text into numerical features by counting the occurrence of each word  called the Bag of Words (BoW) model.\n",
        "\n",
        "| Text                | love | hate | product |\n",
        "| ------------------- | ---- | ---- | ------- |\n",
        "| I love this product | 1    | 0    | 1       |\n",
        "| I hate this product | 0    | 1    | 1       |\n",
        "\n",
        "\n",
        "BoW ignores word order, but captures word frequency, which is often correlated with sentiment.\n",
        "\n",
        " n-Grams\n",
        "\n",
        "n-Grams capture word order and context.\n",
        "An n-gram is a sequence of n words:\n",
        "\n",
        "unigram: \"not\", \"good\"\n",
        "\n",
        "bigram: \"not good\"\n",
        "\n",
        "trigram: \"I dont like\"\n",
        "\n",
        "This helps catch negation or context missed by simple BoW:\n",
        "\n",
        "not good (negative) vs good (positive)\n",
        "\n",
        "\n",
        "Negation and Modifiers\n",
        "\n",
        "Negation flips sentiment:\n",
        "\n",
        "good  positive\n",
        "\n",
        "not good  negative\n",
        "\n",
        "Modifiers amplify or reduce intensity:\n",
        "\n",
        "very good  strongly positive\n",
        "\n",
        "slightly bad  mildly negative\n",
        "\n",
        "Handling these improves model accuracy  often done by custom preprocessing or n-grams.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OQTaYiMG0x8",
        "outputId": "1de835ea-b7f2-4090-f489-ef3a29bdb13b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.00      0.00      0.00         1\n",
            "         pos       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 3. Machine Learning Pipeline (Scikit-learn)\n",
        "\n",
        "# Below is a complete pipeline using Scikit-learn with a Logistic Regression classifier.\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Sample data\n",
        "texts = [\n",
        "    \"I love this movie\",\n",
        "    \"I hate this movie\",\n",
        "    \"This movie is amazing\",\n",
        "    \"This movie is terrible\",\n",
        "    \"I don't like this film\",\n",
        "    \"I really enjoyed the movie\",\n",
        "]\n",
        "labels = [\"pos\", \"neg\", \"pos\", \"neg\", \"neg\", \"pos\"]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build pipeline\n",
        "sentiment_pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1,2))),  # word counts + bigrams\n",
        "    ('tfidf', TfidfTransformer()),                 # term weighting\n",
        "    ('clf', LogisticRegression(max_iter=1000)),    # sentiment classifier\n",
        "])\n",
        "\n",
        "# Train\n",
        "sentiment_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = sentiment_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGzv3t_jZgZf"
      },
      "outputs": [],
      "source": [
        "# Improving with Negation Handling\n",
        "# We can preprocess text to join negations (e.g., not good  not_good):\n",
        "\n",
        "import re\n",
        "\n",
        "def handle_negation(text):\n",
        "    # simple negation handling\n",
        "    text = re.sub(r\"\\bnot\\s+(\\w+)\", r\"not_\\1\", text)\n",
        "    return text\n",
        "\n",
        "# texts = [handle_negation(t.lower()) for t in texts]\n",
        "\n",
        "# Then feed this processed text into the pipeline  now not_good becomes a unique feature, helping the model learn correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2guk7lOapXI",
        "outputId": "c7af9fb8-5b1e-4aaa-d43e-abf75b611f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i love this movie', 'i hate this movie', 'this movie is amazing', 'this movie is terrible', \"i don't like this film\", 'i really enjoyed the movie']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.00      0.00      0.00         1\n",
            "         pos       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# --- 2 Sample dataset ---\n",
        "texts = [\n",
        "    \"I love this movie\",\n",
        "    \"I hate this movie\",\n",
        "    \"This movie is amazing\",\n",
        "    \"This movie is terrible\",\n",
        "    \"I don't like this film\",\n",
        "    \"I really enjoyed the movie\",\n",
        "]\n",
        "labels = [\"pos\", \"neg\", \"pos\", \"neg\", \"neg\", \"pos\"]\n",
        "\n",
        "# --- 3 Apply negation preprocessing before feeding into the model ---\n",
        "texts = [handle_negation(t.lower()) for t in texts]\n",
        "\n",
        "# Example of the transformed text:\n",
        "print(texts)\n",
        "# Output might include: ['i love this movie', 'i hate this movie', 'this movie is amazing', ...]\n",
        "\n",
        "# --- 4 Train/test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- 5 Build the sentiment analysis pipeline ---\n",
        "sentiment_pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(1, 2))),  # BoW + bigrams\n",
        "    ('tfidf', TfidfTransformer()),                  # term weighting\n",
        "    ('clf', LogisticRegression(max_iter=1000)),     # classifier\n",
        "])\n",
        "\n",
        "# --- 6 Train the model ---\n",
        "sentiment_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# --- 7 Evaluate performance ---\n",
        "y_pred = sentiment_pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnePt-3ya0nS"
      },
      "source": [
        "##**DEMO-4.6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96eb6e5",
        "outputId": "aec1e43b-6652-4a0d-83b4-5dc9a524ba4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created dummy 'data/positive-words.txt' and 'data/negative-words.txt'\n"
          ]
        }
      ],
      "source": [
        "# Create dummy positive-words.txt and negative-words.txt for demonstration\n",
        "\n",
        "positive_words_content = \"\"\"\n",
        "; This is a comment\n",
        "; Example positive words\n",
        "good\n",
        "great\n",
        "excellent\n",
        "amazing\n",
        "love\n",
        "happy\n",
        "positive\n",
        "\"\"\"\n",
        "\n",
        "negative_words_content = \"\"\"\n",
        "; This is a comment\n",
        "; Example negative words\n",
        "bad\n",
        "terrible\n",
        "horrible\n",
        "hate\n",
        "sad\n",
        "negative\n",
        "poor\n",
        "\"\"\"\n",
        "\n",
        "# Create 'data' directory if it doesn't exist\n",
        "import os\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Write content to files\n",
        "with open('data/positive-words.txt', 'w') as f:\n",
        "    f.write(positive_words_content)\n",
        "\n",
        "with open('data/negative-words.txt', 'w') as f:\n",
        "    f.write(negative_words_content)\n",
        "\n",
        "print(\"Created dummy 'data/positive-words.txt' and 'data/negative-words.txt'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA6QtHbFax9w",
        "outputId": "d8a24606-8dcb-42e2-c3b1-06a07a55d4af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1794502712.py:3: UserWarning: Input line 1 contained no data and will not be counted towards `max_rows=50000`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
            "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
            "  pos= np.loadtxt('data/positive-words.txt',dtype=str,comments=';')\n",
            "/tmp/ipython-input-1794502712.py:4: UserWarning: Input line 1 contained no data and will not be counted towards `max_rows=50000`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
            "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
            "  neg= np.loadtxt('data/negative-words.txt',dtype=str,comments=';')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pos= np.loadtxt('data/positive-words.txt',dtype=str,comments=';')\n",
        "neg= np.loadtxt('data/negative-words.txt',dtype=str,comments=';')\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh0KIC5slaYJ",
        "outputId": "cf47ce55-fb8a-41e7-d015-6448e7a05f3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['good', 'great', 'excellent', 'amazing', 'love', 'happy',\n",
              "       'positive'], dtype='<U9')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QkaK29pl2VR",
        "outputId": "e69c77f5-f261-46cb-9370-ff6bbcba13b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['bad', 'terrible', 'horrible', 'hate', 'sad', 'negative', 'poor'],\n",
              "      dtype='<U8')"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA38Shk-8Flz"
      },
      "outputs": [],
      "source": [
        "valence ={}\n",
        "\n",
        "for word in pos:\n",
        "    valence[word.lower()]=+1\n",
        "for word in neg:\n",
        "    valence[word.lower()]=-1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDl6WcnviUV1"
      },
      "outputs": [],
      "source": [
        "def sentiment(words,valence):\n",
        "    score=0\n",
        "    word_count=0\n",
        "\n",
        "    for w in words:\n",
        "        if w in valence:\n",
        "            score+=valence[w]\n",
        "            word_count+=1\n",
        "    if word_count == 0:\n",
        "        return 0\n",
        "    print('score',score,'word_count',word_count)\n",
        "    return score/word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enBdhUlYivBm",
        "outputId": "869762bd-0350-442c-aa2a-65627be7b6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'good': 1, 'great': 1, 'excellent': 1, 'amazing': 1, 'love': 1, 'happy': 1, 'positive': 1, 'bad': -1, 'terrible': -1, 'horrible': -1, 'hate': -1, 'sad': -1, 'negative': -1, 'poor': -1}\n"
          ]
        }
      ],
      "source": [
        "print(valence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZGXIYCV_jQrQ",
        "outputId": "cb6ac7b3-daa0-4501-b8c6-d87676086e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score 1 word_count 1\n",
            "excellent product : 1.0\n",
            "score 1 word_count 1\n",
            "not happy product : 1.0\n",
            "score -1 word_count 1\n",
            "what a terrible product : -1.0\n",
            "crazy nevagtive review : 0\n",
            "score -1 word_count 1\n",
            "horrible product : -1.0\n",
            "score -1 word_count 3\n",
            "love the product,but its terrible and horrible : -0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "sample_texts=[\"excellent product\",\"not happy product\",\"what a terrible product\",\"crazy nevagtive review\",\"horrible product\",\"love the product,but its terrible and horrible\"]\n",
        "\n",
        "for sample in sample_texts:\n",
        "    words=nltk.word_tokenize(sample.lower())\n",
        "    print(sample, ':',sentiment(words,valence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSnF3kCDnLja"
      },
      "source": [
        "Using VADER LEXICONS (Continuous weights concepto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDaO_L8vwci2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ddc8HcGw8qp"
      },
      "source": [
        "### TEXT CLASSIFICATION CONCEPTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL6egKNBw8n5"
      },
      "source": [
        "Text classification is the task of assigning predefined categories (labels) to text.\n",
        "Examples:\n",
        "\n",
        "Spam detection: Buy now!  spam\n",
        "\n",
        "Sentiment analysis: I love this movie  positive\n",
        "\n",
        "Topic classification: The stock market is rising  finance\n",
        "\n",
        "The main idea is to convert text into numbers (embeddings) and feed it into a neural network to predict the right label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khATu_oiwTHK"
      },
      "outputs": [],
      "source": [
        "#  Step 1: Preparing Text Data\n",
        "\n",
        "# We need to:\n",
        "\n",
        "# Tokenize text (split into words)\n",
        "\n",
        "# Convert words to integers\n",
        "\n",
        "# Pad/truncate sequences for uniform input size\n",
        "\n",
        "# Create train/test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gK8dR8fwkdD",
        "outputId": "dbc99c52-d6ea-49e9-a03a-a778501c8846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: {'<PAD>': 0, 'i': 1, 'love': 2, 'pytorch': 3, 'deep': 4, 'learning': 5, 'is': 6, 'powerful': 7, 'hate': 8, 'bugs': 9}\n",
            "Encoded + Padded texts:\n",
            " tensor([[1, 2, 3, 0],\n",
            "        [4, 5, 6, 7],\n",
            "        [1, 8, 9, 0]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Example toy dataset\n",
        "texts = [\"I love PyTorch\", \"Deep learning is powerful\", \"I hate bugs\"]\n",
        "labels = [1, 1, 0]  # 1 = positive, 0 = negative\n",
        "\n",
        "# Simple tokenization\n",
        "vocab = {\"<PAD>\": 0}\n",
        "for text in texts:\n",
        "    for word in text.lower().split():\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab)\n",
        "\n",
        "def encode(text):\n",
        "    return torch.tensor([vocab[word] for word in text.lower().split()])\n",
        "\n",
        "encoded_texts = [encode(t) for t in texts]\n",
        "padded_texts = pad_sequence(encoded_texts, batch_first=True, padding_value=0)\n",
        "\n",
        "X = padded_texts\n",
        "y = torch.tensor(labels)\n",
        "\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Encoded + Padded texts:\\n\", X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Av5yDsw2bI"
      },
      "source": [
        " Step 2: Feedforward Neural Network (FFN) for Text Classification\n",
        "\n",
        "A Feedforward Network treats each text as a bag of words (no word order).\n",
        "We average (or sum) word embeddings and pass them into dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKbGWQJewqkM",
        "outputId": "a4d4ff85-ca3f-4685-8301-b1047690bc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FeedForwardTextClassifier(\n",
            "  (embedding): Embedding(10, 16)\n",
            "  (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FeedForwardTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len)\n",
        "        embedded = self.embedding(x)\n",
        "        avg_emb = embedded.mean(dim=1)  # Average pooling\n",
        "        out = F.relu(self.fc1(avg_emb))\n",
        "        return self.fc2(out)\n",
        "\n",
        "model_ffn = FeedForwardTextClassifier(len(vocab), 16, 8, 2)\n",
        "print(model_ffn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cQj5xv6xBJV",
        "outputId": "ecdfd32e-b4f7-4922-f743-dbf3ffcbdd9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7586\n",
            "Epoch 2, Loss: 0.7397\n",
            "Epoch 3, Loss: 0.7264\n",
            "Epoch 4, Loss: 0.7126\n",
            "Epoch 5, Loss: 0.6977\n",
            "Epoch 6, Loss: 0.6817\n",
            "Epoch 7, Loss: 0.6645\n",
            "Epoch 8, Loss: 0.6461\n",
            "Epoch 9, Loss: 0.6262\n",
            "Epoch 10, Loss: 0.6061\n"
          ]
        }
      ],
      "source": [
        "# Training:\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ffn.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_ffn(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9aEV3hxi-h"
      },
      "source": [
        " Step 3: Convolutional Neural Network (CNN) for Text Classification\n",
        "\n",
        "A Text CNN (like Kim, 2014) captures local word patterns  e.g., not good, very happy.\n",
        "It uses 1D convolution filters sliding over embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZNMPsppxkTW",
        "outputId": "f930ca20-0176-4998-c091-6bb5701cfd74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TextCNN(\n",
            "  (embedding): Embedding(10, 16)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(16, 4, kernel_size=(2,), stride=(1,))\n",
            "    (1): Conv1d(16, 4, kernel_size=(3,), stride=(1,))\n",
            "    (2): Conv1d(16, 4, kernel_size=(4,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=12, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes=[2,3,4], num_filters=4):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embed_dim, out_channels=num_filters, kernel_size=k)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)            # (batch, seq_len, embed_dim)\n",
        "        embedded = embedded.permute(0, 2, 1)    # (batch, embed_dim, seq_len)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        pooled = [torch.max(c, dim=2)[0] for c in conved]\n",
        "\n",
        "        cat = torch.cat(pooled, dim=1)\n",
        "        return self.fc(cat)\n",
        "\n",
        "model_cnn = TextCNN(len(vocab), 16, 2)\n",
        "print(model_cnn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypwynJcpxqtC"
      },
      "source": [
        "#Training CNN Concepto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfS4Z7R1xylu",
        "outputId": "5dd2ec82-4fc5-461f-8812-3a65fb1fb8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.4971\n",
            "Epoch 2, Loss: 0.3235\n",
            "Epoch 3, Loss: 0.1922\n",
            "Epoch 4, Loss: 0.1161\n",
            "Epoch 5, Loss: 0.0686\n",
            "Epoch 6, Loss: 0.0391\n",
            "Epoch 7, Loss: 0.0225\n",
            "Epoch 8, Loss: 0.0130\n",
            "Epoch 9, Loss: 0.0076\n",
            "Epoch 10, Loss: 0.0045\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model_cnn.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_cnn(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b772khaXx4gA"
      },
      "source": [
        " Step 4: Comparing FFN vs CNN\n",
        "\n",
        "| Feature        | Feedforward Network       | CNN                            |\n",
        "| -------------- | ------------------------- | ------------------------------ |\n",
        "| Word order     |  Ignored                 |  Captured                     |\n",
        "| Speed          |  Fast                    |  Slightly slower              |\n",
        "| Context window | Global                    | Local (n-grams)                |\n",
        "| Common use     | Simple sentiment or topic | Short text or phrase detection |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-w2UBG4yHjc"
      },
      "source": [
        " Summary\n",
        "\n",
        "| Concept          | Feedforward      | CNN                            |\n",
        "| ---------------- | ---------------- | ------------------------------ |\n",
        "| Handles input as | Bag of words     | Sequence of word patterns      |\n",
        "| Strength         | Simplicity       | Captures local dependencies    |\n",
        "| Weakness         | Loses order info | Limited long-term dependencies |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl2rpAmZyZfY"
      },
      "source": [
        "### ** Project: Sentiment Classification on IMDb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMkOk9OyygAl",
        "outputId": "19b48f5e-b8ab-4e74-eb0e-e6f0878a8442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "O9C3pdegymFI",
        "outputId": "9e95cb0f-dee0-4e84-9987-a0106f3417f1"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1523286307.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: Load the IMDb Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96081451",
        "outputId": "f5becd51-535f-4480-c5cc-ac39573ada98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae000fa4",
        "outputId": "2fb8dd07-46b3-4429-ef2c-743bcafda775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchtext 0.18.0\n",
            "Uninstalling torchtext-0.18.0:\n",
            "  Successfully uninstalled torchtext-0.18.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1+cu116 (from versions: 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1+cu116\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchtext -y\n",
        "!pip install torch==1.13.1+cu116 torchtext==0.14.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sl-ldlv0EBt",
        "outputId": "146a05d1-051a-415d-9a67-24bd1acc9bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.9.0 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.9.0 which is incompatible.\n",
            "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torchtext --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kuzLo0c0UZ3",
        "outputId": "e7999c8e-2580-4c60-f6f1-666859cadfcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TFU8tlwz7-6",
        "outputId": "8109661d-23de-4c8e-d21b-2209563928cb"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3962232932.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: Load the IMDb Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0minspected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mlibraries\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_"
          ]
        }
      ],
      "source": [
        "# Step 2: Load the IMDb Dataset\n",
        "\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Load dataset\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for label, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "print(\"Vocab size:\", len(vocab))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj4M3UB5rzZ73Xclk7s4jl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}